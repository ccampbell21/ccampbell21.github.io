<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Caroline Campbell" />
    
    <link rel="shortcut icon" type="image/x-icon" href="../../img/favicon.ico">
    <title>Project 2: Medical School Acceptances</title>
    <meta name="generator" content="Hugo 0.83.1" />
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="../../css/main.css" />
    <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" />
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,400,200bold,400old" />
    
    <!--[if lt IE 9]>
			<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
			<script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
		<![endif]-->

    
  </head>

  <body>
    <div id="wrap">
      
      <nav class="navbar navbar-default">
  <div class="container">
    <div class="navbar-header">
      <a class="navbar-brand" href="../../"><i class="fa fa-home"></i></a>
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <div class="navbar-collapse collapse" id="navbar">
      <ul class="nav navbar-nav navbar-right">
      
        
        <li><a href="../../post/">BLOG</a></li>
        
        <li><a href="../../projects/">PROJECTS</a></li>
        
        <li><a href="../../resume/">RESUME</a></li>
        
      
      </ul>
    </div>
  </div>
</nav>

      <div class="container">
        <div class="blog-post">
          <h3>
            <strong><a href="../../project/project2/">Project 2: Medical School Acceptances</a></strong>
          </h3>
        </div>
 
<div class="blog-title">
          <h4>
         January 1, 0001 
            &nbsp;&nbsp;
            
          </h4>
        </div>

        <div class="panel panel-default">
          <div class="panel-body">
            <div class="blogpost">
              


<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>The dataset <code>MedGPA</code> contains information about the status of medical school admissions, GPA, and MCAT scores from 55 undergraduate students (observations) from a Midwest liberal arts college that were medical school applicants. There are 11 variables: <code>Accept</code>, <code>Acceptance</code>, <code>Sex</code>, <code>BCPM</code>, <code>GPA</code>, <code>VR</code>, <code>PS</code>, <code>WS</code>, <code>BS</code>, <code>MCAT</code>, and <code>Apps</code>. <code>Accept</code> indicates whether the applicant was accepted or denied after applying, and <code>Acceptance</code> is binary for <code>Accept</code> with 1 = accepted, and 0 = denied. <code>Sex</code> illustrates whether the applicant was male or female, and their respective college grade point average is measured as <code>GPA</code>. Their biology/chemistry/physics/math (or science) GPA is indicated with <code>BCPM</code>. The <code>VR</code>, <code>PS</code>, <code>WS</code>, and <code>BS</code>measure the verbal reasoning, physical sciences, writing sample, and biological sciences subscore of their total <code>MCAT</code> score (i.e., the sum of those variables is equal to <code>MCAT</code>). Lastly, the <code>Apps</code> variable is a measure of the total number of medical schools that the applicant applied to.</p>
<pre class="r"><code>MedGPA &lt;- read_csv(&quot;MedGPA.csv&quot;)
#Turning factors to categorical and intervals to numeric
MedGPA$Accept&lt;-as.character(MedGPA$Accept)
MedGPA$Sex&lt;-as.character(MedGPA$Sex)
MedGPA$VR&lt;-as.numeric(MedGPA$VR)
MedGPA$PS&lt;-as.numeric(MedGPA$PS)
MedGPA$WS&lt;-as.numeric(MedGPA$WS)
MedGPA$BS&lt;-as.numeric(MedGPA$BS)
MedGPA$MCAT&lt;-as.numeric(MedGPA$MCAT)
MedGPA$Apps&lt;-as.numeric(MedGPA$Apps)
#renaming 
MedGPA&lt;-MedGPA%&gt;% select(-X1) %&gt;% mutate(Sex=recode(Sex, F=&quot;female&quot;, M=&quot;male&quot;)) %&gt;% mutate(Accept=recode(Accept,D=&quot;denied&quot;,A=&quot;accepted&quot;))

head(MedGPA)</code></pre>
<pre><code>## # A tibble: 6 x 11
## Accept Acceptance Sex BCPM GPA VR PS WS BS MCAT Apps
## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
&lt;dbl&gt; &lt;dbl&gt;
## 1 denied 0 female 3.59 3.62 11 9 9 9 38 5
## 2 accepted 1 male 3.75 3.84 12 13 8 12 45 3
## 3 accepted 1 female 3.24 3.23 9 10 5 9 33 19
## 4 accepted 1 female 3.74 3.69 12 11 7 10 40 5
## 5 accepted 1 female 3.53 3.38 9 11 4 11 35 11
## 6 accepted 1 male 3.59 3.72 10 9 7 10 36 5</code></pre>
</div>
<div id="manova" class="section level1">
<h1>MANOVA</h1>
<pre class="r"><code>#MANOVA
MedGPAmanova &lt;- manova(cbind(BCPM, GPA, MCAT, Apps)~Accept, data=MedGPA)
summary(MedGPAmanova)</code></pre>
<pre><code>## Df Pillai approx F num Df den Df Pr(&gt;F)
## Accept 1 0.31559 5.764 4 50 0.0006788 ***
## Residuals 53
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>#Univariate ANOVAs
summary.aov(MedGPAmanova)</code></pre>
<pre><code>## Response BCPM :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## Accept 1 1.6922 1.69216 18.219 8.179e-05 ***
## Residuals 53 4.9225 0.09288
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Response GPA :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## Accept 1 1.2947 1.29472 21.879 2.043e-05 ***
## Residuals 53 3.1363 0.05918
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Response MCAT :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## Accept 1 212.4 212.402 10.819 0.001789 **
## Residuals 53 1040.5 19.632
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Response Apps :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## Accept 1 3.5 3.5006 0.1529 0.6973
## Residuals 53 1213.2 22.8911</code></pre>
<pre class="r"><code>#post-hoc t tests for significant ANOVAs
pairwise.t.test(MedGPA$BCPM,MedGPA$Accept, p.adj=&quot;none&quot;)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  MedGPA$BCPM and MedGPA$Accept 
## 
##        accepted
## denied 8.2e-05 
## 
## P value adjustment method: none</code></pre>
<pre class="r"><code>pairwise.t.test(MedGPA$GPA,MedGPA$Accept, p.adj=&quot;none&quot;)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  MedGPA$GPA and MedGPA$Accept 
## 
##        accepted
## denied 2e-05   
## 
## P value adjustment method: none</code></pre>
<pre class="r"><code>pairwise.t.test(MedGPA$MCAT,MedGPA$Accept, p.adj=&quot;none&quot;)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  MedGPA$MCAT and MedGPA$Accept 
## 
##        accepted
## denied 0.0018  
## 
## P value adjustment method: none</code></pre>
<pre class="r"><code>#type-I error rate
1-(0.95^8)</code></pre>
<pre><code>## [1] 0.3365796</code></pre>
<pre class="r"><code>#bonferonni adjustment
0.05/8</code></pre>
<pre><code>## [1] 0.00625</code></pre>
<pre class="r"><code>##ASSUMPTIONS
library(rstatix)
group &lt;- MedGPA$Accept
DVs &lt;- MedGPA %&gt;% select(BCPM, GPA, MCAT, Apps)
#Test multivariate normality for each group (null: normality met)
sapply(split(DVs,group), mshapiro_test)</code></pre>
<pre><code>##           accepted  denied      
## statistic 0.9533242 0.832119    
## p.value   0.2073555 0.0008212247</code></pre>
<pre class="r"><code>#Test homogeneity of covariance-Box&#39;s M test (null: homogeneity of vcov mats assumption met)
box_m(DVs, group)</code></pre>
<pre><code>## # A tibble: 1 x 4
## statistic p.value parameter method
## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;
## 1 7.03 0.723 10 Box&#39;s M-test for Homogeneity of
Covariance Matrices</code></pre>
<p>After running <code>MedGPAmanova</code>, there is at least one acceptance that differs for at least one response variable (<code>BCPM</code>, <code>GPA</code>, <code>MCAT</code>, <code>Apps</code>) (Pillai trace=0.31559, pseudo F (450)=5.764, p=0.0006788). There is a significant difference in <code>BCPM</code>, <code>GPA</code>, and <code>MCAT</code> between acceptances (F = 18.219, df = 53, p = 8.179e-05), (F = 21.879, df = 53, p = 2.043e-05), (F = 10.819, df = 53, p = 0.001789), respectively. There were 8 tests done in all (1 MANOVA, 4 ANOVAs, and 3 post-hoc t tests) with an overall type-I error rate of 0.3368, so a (bonferroni adjusted) significance level should be 0.00625 to keep the overall type-I error rate at 0.05. Out of the 3 significant post hoc tests before adjustment, they are all still significant. After testing a few of the MANOVA assumptions, the assumption of random samples and independent observations was likely met. Because we fail to reject the null for <code>accepted</code> based on the dependent variables (p-value=0.207), normality was met, but the <code>denied</code> group rejected the null (0.0008), which means normality was not met. The Box’s M test p-value was 0.723, so we fail to reject the null, meaning the homogeneity of vcov mats assumption was met.</p>
</div>
<div id="randomization-test-correlation" class="section level1">
<h1>Randomization Test: Correlation</h1>
<pre class="r"><code>set.seed(348)
cors &lt;- vector()
for(i in 1:5000){
cors[i] &lt;- MedGPA %&gt;% slice(sample(1:n(),replace=T))%&gt;%summarize(cor(BCPM,MCAT)) %&gt;% pull
}
#visualization
hist(cors)</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-3-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#correlation
MedGPA %&gt;% select(BCPM, MCAT) %&gt;% cor()</code></pre>
<pre><code>##           BCPM      MCAT
## BCPM 1.0000000 0.5153093
## MCAT 0.5153093 1.0000000</code></pre>
<pre class="r"><code>#95% confidence interval
quantile(cors,c(.025, .975))#significantly different because 0 is not between the two </code></pre>
<pre><code>##      2.5%     97.5% 
## 0.2604968 0.6999446</code></pre>
<p>The null hypothesis is that there is no linear correlation (i.e., the correlation coefficient is 0). The alternative hypothesis is that there is a linear correlation (i.e., the correlation coefficient is not equal to 0). The 95% confidence interval does not include 0 between the lower 2.5% and upper 97.5%, so we can reject the null hypothesis. Thus, there is a significant linear correlation between BCPM and MCAT scores. The lower limit of the bootstrapped 95% confidence interval is 0.26, and the upper limit is 0.6999.</p>
</div>
<div id="linear-regression" class="section level1">
<h1>Linear Regression</h1>
<pre class="r"><code>library(sandwich)
library(lmtest)
#centering MCAT
MedGPA$MCAT_c &lt;- MedGPA$MCAT - mean(MedGPA$MCAT, na.rm=T)
fit&lt;-lm(GPA~Accept*MCAT_c, data=MedGPA)
summary(fit)</code></pre>
<pre><code>##
## Call:
## lm(formula = GPA ~ Accept * MCAT_c, data = MedGPA)
##
## Residuals:
## Min 1Q Median 3Q Max
## -0.6211 -0.1342 -0.0027 0.1585 0.3597
##
## Coefficients:
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 3.648425 0.044935 81.194 &lt; 2e-16 ***
## Acceptdenied -0.218452 0.066970 -3.262 0.00198 **
## MCAT_c 0.025033 0.010078 2.484 0.01632 *
## Acceptdenied:MCAT_c -0.004235 0.013981 -0.303 0.76319
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Residual standard error: 0.2253 on 51 degrees of freedom
## Multiple R-squared: 0.4157, Adjusted R-squared: 0.3813
## F-statistic: 12.09 on 3 and 51 DF, p-value: 4.288e-06</code></pre>
<pre class="r"><code>#visualization
MedGPA %&gt;% select(GPA, MCAT, Accept) %&gt;% na.omit %&gt;% 
    ggplot(aes(MCAT, GPA, color = Accept)) + 
    geom_point() + geom_smooth(method = &quot;lm&quot;) + geom_vline(xintercept = mean(MedGPA$MCAT, 
    na.rm = T), lty = 2)</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-4-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#proportion of variation
summary(fit)$r.sq </code></pre>
<pre><code>## [1] 0.4156693</code></pre>
<pre class="r"><code>#testing homoskedasticity assumption- Ho: homoskedsastic
bptest(fit)  #p-value &gt; 0.05 = fail to reject null</code></pre>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  fit
## BP = 2.6577, df = 3, p-value = 0.4475</code></pre>
<pre class="r"><code>#testing normality assumption
resids&lt;-fit$residuals
ggplot()+geom_histogram(aes(resids), bins=20)</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-4-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>shapiro.test(resids) #Ho: true distribution is normal</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  resids
## W = 0.96794, p-value = 0.1486</code></pre>
<pre class="r"><code>#testing linearity assumption
fitted&lt;-fit$fitted.values
ggplot()+geom_point(aes(fitted,resids))+geom_hline(yintercept=0, color=&#39;red&#39;)</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-4-3.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#robust standard errors
coeftest(fit, vcov = vcovHC(fit))</code></pre>
<pre><code>##
## t test of coefficients:
##
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 3.6484250 0.0441074 82.7168 &lt; 2.2e-16 ***
## Acceptdenied -0.2184519 0.0702841 -3.1081 0.0030762 **
## MCAT_c 0.0250333 0.0063938 3.9153 0.0002689 ***
## Acceptdenied:MCAT_c -0.0042350 0.0182837 -0.2316
0.8177535
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<p>The mean/predicted GPA for accepted students with a score of zero on the MCAT is 3.648. For every one-unit increase in <code>MCAT</code>, the predicted <code>GPA</code> goes up by 0.025 for those that are accepted. For every one-unit increase in <code>Acceptdenied</code>, the predicted <code>GPA</code> goes down by 0.218. The slope of <code>MCAT</code> on <code>GPA</code> for <code>Acceptdenied</code> is 0.004 less than for <code>Acceptaccepted</code>. The model explains 0.4157 of the variation in the outcome. When testing the assumption of homoskedasticity, we fail to reject the null hypothesis, so we have met the homoskedastic assumption (BP=2.658, df=3, p-value=0.448). We can also fail to reject the null for the Shapiro-Wilk test, so the distribution is normal (W=0.968, p-value=0.149). The scatterplot illustrates that the linearity assumption was met. Redoing the regression using robust standard errors, the p-vlaue for <code>Acceptdenied</code> increased slightly but is still significant, and the standard error is roughly the same. The p-vlaue for <code>MCAT_c</code> decreased slightly but is still significant after using robust standard errors, and the standard error decreased by roughly 0.004. Because both are still significant, we reject the null. The interaction <code>Acceptdenied:MCAT_c</code> had an increase in the p-value and standard errors, but the results remained the same in that we fail to reject the null. The intercept remained relatively steady and still has the same results (reject the null).</p>
</div>
<div id="rerunning-regression-model" class="section level1">
<h1>Rerunning Regression Model</h1>
<pre class="r"><code># resampling residuals
fit&lt;-lm(GPA~Accept*MCAT_c, data=MedGPA)
resids &lt;- fit$residuals  #save residuals
fitted &lt;- fit$fitted.values  #save yhats

set.seed(348)
resid_resamp &lt;- replicate(5000, {
    new_resids &lt;- sample(resids, replace = TRUE)  #resample resids w/ replacement
    MedGPA$new_GPA &lt;- fitted + new_resids  #add new resids to yhats to get new &#39;data&#39;
    fit &lt;- lm(new_GPA ~ Accept*MCAT_c, data = MedGPA)  #refit model
    coef(fit)  #save coefficient estimates (b0, b1, etc)
})
## Estimated SEs
resid_resamp %&gt;% t %&gt;% as.data.frame %&gt;% summarize_all(sd)</code></pre>
<pre><code>## (Intercept) Acceptdenied MCAT_c Acceptdenied:MCAT_c
## 1 0.0424387 0.06356751 0.009739742 0.01326808</code></pre>
<p>The boostrap standard error resampling residuals were very close to the original standard errors. The resampled residuals were only slightly less than the original standard errors, and the difference between them and the robust standard errors was greater (i.e., most of the robust standard errors were larger). Because it matches the original model and that resampling residuals assumes that the original model is correct, we would still reject the null hypothesis for <code>Acceptdenied</code> and <code>MCAT_c</code>.</p>
</div>
<div id="logistic-regression" class="section level1">
<h1>Logistic Regression</h1>
<pre class="r"><code>library(plotROC)
fit2&lt;-glm(Acceptance~Sex+MCAT, data=MedGPA, family=&quot;binomial&quot;)
coeftest(fit2)</code></pre>
<pre><code>##
## z test of coefficients:
##
## Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept) -8.951419 3.353909 -2.6690 0.007609 **
## Sexmale -1.066245 0.633348 -1.6835 0.092277 .
## MCAT 0.266892 0.094071 2.8371 0.004552 **
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>exp(coef(fit2))</code></pre>
<pre><code>##  (Intercept)      Sexmale         MCAT 
## 0.0001295533 0.3442990112 1.3058995224</code></pre>
<pre class="r"><code>#confusion matrix
prob&lt;-predict(fit2,type=&quot;response&quot;)
table(predict=as.numeric(prob&gt;.5),truth=MedGPA$Acceptance)%&gt;%addmargins</code></pre>
<pre><code>##        truth
## predict  0  1 Sum
##     0   15  5  20
##     1   10 25  35
##     Sum 25 30  55</code></pre>
<pre class="r"><code>#Accuracy = 0.727
(15+25)/55</code></pre>
<pre><code>## [1] 0.7272727</code></pre>
<pre class="r"><code>#Sensitivity (TPR)=0.833
25/30</code></pre>
<pre><code>## [1] 0.8333333</code></pre>
<pre class="r"><code>#Specificity (TNR)=0.6
15/25</code></pre>
<pre><code>## [1] 0.6</code></pre>
<pre class="r"><code>#Precision (PPV)=0.714
25/35</code></pre>
<pre><code>## [1] 0.7142857</code></pre>
<pre class="r"><code>#Density plot of logit
MedGPA$logit&lt;-predict(fit2,type=&quot;link&quot;) #get log-odds for everyone
MedGPA%&gt;%ggplot()+geom_density(aes(logit,color=Accept,fill=Accept), alpha=.4)+
  theme(legend.position=c(.85,.85))+geom_vline(xintercept=0)+xlab(&quot;logit (log-odds)&quot;)+
  geom_rug(aes(logit,color=Accept))+
  ggtitle(&quot;Density Plot of Log-odds (logit)&quot;)+
  theme(plot.title = element_text(hjust = 0.5))</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-6-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#ROC curve
ROCplot&lt;-ggplot(MedGPA)+geom_roc(aes(d=Acceptance,m=prob), n.cuts=0) 
ROCplot</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-6-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#AUC =0.77 = fair
calc_auc(ROCplot)</code></pre>
<pre><code>##   PANEL group  AUC
## 1     1    -1 0.77</code></pre>
<p>The odds of being accepted for female students is 0.00013. The odds of being accepted for male students are 0.344 times that of female students. Lastly, the odds of acceptance for females based on <code>MCAT</code> is 1.306. The accuracy is 0.727, sensitivity (TPR) is 0.833, specificity (TNR) is 0.6, and precision (PPV) is 0.714. All of the values are not extremely high. However, they are above 0.5, and are relatively fair, so the overall outcome is good. From the ROC plot and calculating the AUC to be 0.77, the sensitivity and specificity is considered “fair” because AUC summarizes both values into one.</p>
</div>
<div id="logistic-regression-all-variables" class="section level1">
<h1>Logistic Regression: All Variables</h1>
<pre class="r"><code>MedGPA2&lt;-MedGPA %&gt;% na.omit() %&gt;% select(-Accept, -logit)
fit3&lt;-glm(Acceptance~., data=MedGPA2, family=&quot;binomial&quot;)
prob2 &lt;- predict(fit3,type=&quot;response&quot;)
#In-sample Classification Diagnostics
class_diag(prob2, MedGPA2$Acceptance)</code></pre>
<pre><code>##         acc sens  spec ppv  auc
## 1 0.8888889  0.9 0.875 0.9 0.95</code></pre>
<pre class="r"><code>#10-fold CV
set.seed(1234)
k=10 #choose number of folds
data&lt;-MedGPA2[sample(nrow(MedGPA2)),] #randomly order rows
folds&lt;-cut(seq(1:nrow(MedGPA2)),breaks=k,labels=F) #create folds
diags&lt;-NULL
for(i in 1:k){
  ## Create training and test sets
  train&lt;-data[folds!=i,]
  test&lt;-data[folds==i,]
  truth&lt;-test$Acceptance ## Truth labels for fold i
  ## Train model on training set (all but fold i)
  fit3&lt;-glm(Acceptance~.,data=train,family=&quot;binomial&quot;)
  ## Test model on test set (fold i)
  probs&lt;-predict(fit3,newdata = test,type=&quot;response&quot;)
  ## Get diagnostics for fold i
  diags&lt;-rbind(diags,class_diag(probs,truth))
}
summarize_all(diags,mean) #average diagnostics across all k folds</code></pre>
<pre><code>##    acc  sens      spec       ppv       auc
## 1 0.78 0.775 0.8266667 0.8333333 0.8994444</code></pre>
<pre class="r"><code>#LASSO
library(glmnet)
set.seed(1234)

y&lt;-as.matrix(MedGPA2$Acceptance) #grab response
x&lt;-model.matrix(Acceptance~.,data=MedGPA2)[,-1]#grab predictors
head(x)</code></pre>
<pre><code>##   Sexmale BCPM  GPA VR PS WS BS MCAT Apps     MCAT_c
## 1       0 3.59 3.62 11  9  9  9   38    5  1.7272727
## 2       1 3.75 3.84 12 13  8 12   45    3  8.7272727
## 3       0 3.24 3.23  9 10  5  9   33   19 -3.2727273
## 4       0 3.74 3.69 12 11  7 10   40    5  3.7272727
## 5       0 3.53 3.38  9 11  4 11   35   11 -1.2727273
## 6       1 3.59 3.72 10  9  7 10   36    5 -0.2727273</code></pre>
<pre class="r"><code>cv&lt;-cv.glmnet(x,y,family=&quot;binomial&quot;)
lasso&lt;-glmnet(x,y,family=&quot;binomial&quot;,lambda=cv$lambda.1se)
coef(lasso)</code></pre>
<pre><code>## 11 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                       s0
## (Intercept) -14.72542379
## Sexmale      -0.57864832
## BCPM          .         
## GPA           2.25362630
## VR            .         
## PS            0.18495994
## WS           -0.03764313
## BS            0.58161467
## MCAT          .         
## Apps          .         
## MCAT_c        .</code></pre>
<pre class="r"><code>#10-fold CV (with LASSO variables)
MedGPA3&lt;-MedGPA2%&gt;%mutate(Male=ifelse(Sex==&quot;Male&quot;,1,0))
set.seed(1234)
k=10 #choose number of folds
data&lt;-MedGPA3[sample(nrow(MedGPA3)),] #randomly order rows
folds&lt;-cut(seq(1:nrow(MedGPA3)),breaks=k,labels=F) #create folds
diags&lt;-NULL
for(i in 1:k){
  ## Create training and test sets
  train&lt;-data[folds!=i,]
  test&lt;-data[folds==i,]
  truth&lt;-test$Acceptance ## Truth labels for fold i
  ## Train model on training set (all but fold i)
  fit4&lt;-glm(Acceptance~Male+GPA+PS+WS+BS,data=train,family=&quot;binomial&quot;)
  ## Test model on test set (fold i)
  probs&lt;-predict(fit4,newdata = test,type=&quot;response&quot;)
  ## Get diagnostics for fold i
  diags&lt;-rbind(diags,class_diag(probs,truth))
}
summarize_all(diags,mean) #average diagnostics across all k folds</code></pre>
<pre><code>##    acc      sens      spec  ppv       auc
## 1 0.82 0.8666667 0.7766667 0.83 0.8786111</code></pre>
<p>When predicting <code>Acceptance</code> from the rest of the variables, the in-sample classification diagnostics were 0.889 for accuracy, 0.9 for sensitivity, 0.875 for specificity, 0.9 for precision, and 0.95 for AUC. The AUC is considered great. After performing a 10-fold cross-validation with the same model, the accuracy was 0.78, sensitivity was 0.775, specificity was 0.8267, precision was 0.833, and the ACU was 0.899. The AUC decreased from the in-sample metrics, but it can be considered “good”. Because it decreased, the model was overfit. After performing LASSO, the <code>sexmale</code>, <code>GPA</code>, <code>PS</code>, <code>WS</code>, and <code>BS</code> variables were retained. When using the variables chosen by LASSO for 10-fold cross validation, the accuracy was 0.82, sensitivity was 0.867, specificity was 0.777, precision was 0.83, and the AUC was 0.879. All of the values were worse than the in-sample classification diagnostics, but were slightly better than the first 10-fold cross validation, except the specificity, precision, and AUC were worse. However, the AUC is still considered “good”.</p>
</div>

            
        <hr>         <div class="related-posts">
                <h5>Related Posts</h5>
                
              </div> 
            </div>
          </div>

   <hr>  <div class="disqus">
  <div id="disqus_thread"></div>
  <script type="text/javascript">

    (function() {
      
      
      if (window.location.hostname == "localhost")
        return;

      var disqus_shortname = '';
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div> 
        </div>
      </div>
    </div>

    
    <footer>
  <div id="footer">
    <div class="container">
      <p class="text-muted">&copy; All rights reserved. Powered by <a href="https://gohugo.io/">Hugo</a> and
      <a href="http://www.github.com/nurlansu/hugo-sustain/">sustain</a> with ♥</p>
    </div>
  </div>
</footer>
<div class="footer"></div>


<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script src="../../js/docs.min.js"></script>
<script src="../../js/main.js"></script>

<script src="../../js/ie10-viewport-bug-workaround.js"></script>


    
  </body>
</html>
